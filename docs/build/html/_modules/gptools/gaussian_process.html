<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>gptools.gaussian_process &mdash; gptools 0.2 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="gptools 0.2 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">gptools 0.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for gptools.gaussian_process</h1><div class="highlight"><pre>
<span class="c"># Copyright 2014 Mark Chilenski</span>
<span class="c"># This program is distributed under the terms of the GNU General Purpose License (GPL).</span>
<span class="c"># Refer to http://www.gnu.org/licenses/gpl.txt</span>
<span class="c"># </span>
<span class="c"># This program is free software: you can redistribute it and/or modify</span>
<span class="c"># it under the terms of the GNU General Public License as published by</span>
<span class="c"># the Free Software Foundation, either version 3 of the License, or</span>
<span class="c"># (at your option) any later version.</span>
<span class="c"># </span>
<span class="c"># This program is distributed in the hope that it will be useful,</span>
<span class="c"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c"># GNU General Public License for more details.</span>
<span class="c"># </span>
<span class="c"># You should have received a copy of the GNU General Public License</span>
<span class="c"># along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>

<span class="sd">&quot;&quot;&quot;Provides the base :py:class:`GaussianProcess` class.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>

<span class="kn">from</span> <span class="nn">.error_handling</span> <span class="kn">import</span> <span class="n">GPArgumentError</span>
<span class="kn">from</span> <span class="nn">.kernel</span> <span class="kn">import</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">ZeroKernel</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">wrap_fmin_slsqp</span><span class="p">,</span> <span class="n">univariate_envelope_plot</span><span class="p">,</span> <span class="n">CombinedBounds</span><span class="p">,</span> <span class="n">unique_rows</span><span class="p">,</span> <span class="n">plot_sampler</span>

<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">import</span> <span class="nn">numpy.random</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">emcee</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;Could not import emcee: MCMC sampling will not be available.&quot;</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">triangle</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;Could not import triangle: plotting of MCMC results will not &quot;</span>
                  <span class="s">&quot;be available.&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="GaussianProcess"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess">[docs]</a><span class="k">class</span> <span class="nc">GaussianProcess</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">r&quot;&quot;&quot;Gaussian process.</span>
<span class="sd">    </span>
<span class="sd">    If called with one argument, an untrained Gaussian process is constructed</span>
<span class="sd">    and data must be added with the :py:meth:`add_data` method. If called with</span>
<span class="sd">    the optional keywords, the values given are used as the data. It is always</span>
<span class="sd">    possible to add additional data with :py:meth:`add_data`.</span>
<span class="sd">    </span>
<span class="sd">    Note that the attributes have no write protection, but you should always</span>
<span class="sd">    add data with :py:meth:`add_data` to ensure internal consistency.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : :py:class:`~gptools.kernel.core.Kernel` instance</span>
<span class="sd">        Kernel instance corresponding to the desired noise-free covariance</span>
<span class="sd">        kernel of the Gaussian process. The noise is handled separately either</span>
<span class="sd">        through specification of `err_y`, or in a separate kernel. This allows</span>
<span class="sd">        noise-free predictions when needed.</span>
<span class="sd">    noise_k : :py:class:`~gptools.kernel.core.Kernel` instance</span>
<span class="sd">        Kernel instance corresponding to the noise portion of the desired</span>
<span class="sd">        covariance kernel of the Gaussian process. Note that you DO NOT need to</span>
<span class="sd">        specify this if the extent of the noise you want to represent is</span>
<span class="sd">        contained in `err_y` (or if your data are noiseless). Default value is</span>
<span class="sd">        None, which results in the :py:class:`~gptools.kernel.noise.ZeroKernel`</span>
<span class="sd">        (noise specified elsewhere or not present).</span>
<span class="sd">    diag_factor : float, optional</span>
<span class="sd">        Factor of :py:attr:`sys.float_info.epsilon` which is added to the</span>
<span class="sd">        diagonal of the total `K` matrix to improve the stability of the</span>
<span class="sd">        Cholesky decomposition. If you are having issues, try increasing this by</span>
<span class="sd">        a factor of 10 at a time. Default is 1e2.</span>
<span class="sd">    mu : :py:class:`~gptools.mean.MeanFunction` instance</span>
<span class="sd">        The mean function of the Gaussian process. Default is None (zero mean</span>
<span class="sd">        prior).</span>
<span class="sd">    </span>
<span class="sd">    NOTE</span>
<span class="sd">        The following are all passed to :py:meth:`add_data`, refer to its</span>
<span class="sd">        docstring.</span>
<span class="sd">    </span>
<span class="sd">    X : array, (`M`, `D`), optional</span>
<span class="sd">        `M` input values of dimension `D`. Default value is None (no data).</span>
<span class="sd">    y : array, (`M`,), optional</span>
<span class="sd">        `M` data target values. Default value is None (no data).</span>
<span class="sd">    err_y : array, (`M`,), optional</span>
<span class="sd">        Error (given as standard deviation) in the `M` training target values.</span>
<span class="sd">        Default value is 0 (noiseless observations).</span>
<span class="sd">    n : array, (`M`, `D`) or scalar float, optional</span>
<span class="sd">        Non-negative integer values only. Degree of derivative for each target.</span>
<span class="sd">        If `n` is a scalar it is taken to be the value for all points in `y`.</span>
<span class="sd">        Otherwise, the length of n must equal the length of `y`. Default value</span>
<span class="sd">        is 0 (observation of target value). If non-integer values are passed,</span>
<span class="sd">        they will be silently rounded.</span>
<span class="sd">    T : array, (`M`, `N`), optional</span>
<span class="sd">        Linear transformation to get from latent variables to data in the</span>
<span class="sd">        argument `y`. When `T` is passed the argument `y` holds the transformed</span>
<span class="sd">        quantities `y=TY(X)` where `y` are the observed values of the</span>
<span class="sd">        transformed quantities, `T` is the transformation matrix and `Y(X)` is</span>
<span class="sd">        the underlying (untransformed) values of the function to be fit that</span>
<span class="sd">        enter into the transformation. When `T` is `M`-by-`N` and `y` has `M`</span>
<span class="sd">        elements, `X` and `n` will both be `N`-by-`D`. Default is None (no</span>
<span class="sd">        transformation).</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    k : :py:class:`~gptools.kernel.core.Kernel` instance</span>
<span class="sd">        The non-noise portion of the covariance kernel.</span>
<span class="sd">    noise_k : :py:class:`~gptools.kernel.core.Kernel` instance</span>
<span class="sd">        The noise portion of the covariance kernel.</span>
<span class="sd">    X : array, (`M`, `D`)</span>
<span class="sd">        The `M` training input values, each of which is of dimension `D`.</span>
<span class="sd">    y : array, (`M`,)</span>
<span class="sd">        The `M` training target values.</span>
<span class="sd">    err_y : array, (`M`,)</span>
<span class="sd">        The error in the `M` training input values.</span>
<span class="sd">    n : array, (`M`, `D`)</span>
<span class="sd">        The orders of derivatives that each of the `M` training points represent, indicating the order of derivative with respect to each of the `D` dimensions.</span>
<span class="sd">    T : array, (`M`, `N`)</span>
<span class="sd">        The transformation matrix applied to the data. If this is not None, `X` and `n` will be `N`-by-`D`.</span>
<span class="sd">    K_up_to_date : bool</span>
<span class="sd">        True if no data have been added since the last time the internal state was updated with a call to :py:meth:`compute_K_L_alpha_ll`.</span>
<span class="sd">    K : array, (`M`, `M`)</span>
<span class="sd">        Covariance matrix between all of the training inputs.</span>
<span class="sd">    noise_K : array, (`M`, `M`)</span>
<span class="sd">        Noise portion of the covariance matrix between all of the training inputs. Only includes the noise from :py:attr:`noise_k`, not from :py:attr:`err_y`.</span>
<span class="sd">    L : array, (`M`, `M`)</span>
<span class="sd">        Cholesky decomposition of the combined covariance matrix between all of the training inputs.</span>
<span class="sd">    alpha : array, (`M`, 1)</span>
<span class="sd">        Solution to :math:`K\alpha=y`.</span>
<span class="sd">    ll : float</span>
<span class="sd">        Log-likelihood of the data given the model.</span>
<span class="sd">    diag_factor : float</span>
<span class="sd">        The factor of :py:attr:`sys.float_info.epsilon` which is added to the diagonal of the `K` matrix to improve stability.</span>
<span class="sd">    mu : :py:class:`~gptools.mean.MeanFunction` instance</span>
<span class="sd">        The mean function.</span>
<span class="sd">        </span>
<span class="sd">    </span>
<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    GPArgumentError</span>
<span class="sd">        Gave `X` but not `y` (or vice versa).</span>
<span class="sd">    ValueError</span>
<span class="sd">        Training data rejected by :py:meth:`add_data`.</span>
<span class="sd">    </span>
<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    add_data : Used to process `X`, `y`, `err_y` and to add data to the process.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">noise_k</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">err_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">diag_factor</span><span class="o">=</span><span class="mf">1e2</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s">&quot;Argument k must be an instance of Kernel when constructing &quot;</span>
                <span class="s">&quot;GaussianProcess!&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">noise_k</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">noise_k</span> <span class="o">=</span> <span class="n">ZeroKernel</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">noise_k</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s">&quot;Keyword noise_k must be an instance of Kernel when &quot;</span>
                    <span class="s">&quot;constructing GaussianProcess!&quot;</span>
                <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diag_factor</span> <span class="o">=</span> <span class="n">diag_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span> <span class="o">=</span> <span class="n">noise_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">GPArgumentError</span><span class="p">(</span>
                    <span class="s">&quot;Must pass both X and y when constructing GaussianProcess!&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">err_y</span><span class="o">=</span><span class="n">err_y</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">X</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">GPArgumentError</span><span class="p">(</span>
                <span class="s">&quot;Must pass both X and y when constructing GaussianProcess!&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="c"># The following are getters/setters for the (hyper)parameters of the model.</span>
    <span class="c"># Right now they pull from the kernel, noise kernel and mean function.</span>
    <span class="c"># Modify them to add more complicated things you want to infer.</span>
    
    <span class="c"># TODO: These getters don&#39;t handle assignment by index!</span>
    
    <span class="nd">@property</span>
<div class="viewcode-block" id="GaussianProcess.hyperprior"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.hyperprior">[docs]</a>    <span class="k">def</span> <span class="nf">hyperprior</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Combined hyperprior for the kernel, noise kernel and (if present) mean function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">hyperprior</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">hyperprior</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">hp</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">hyperprior</span>
        <span class="k">return</span> <span class="n">hp</span>
    
    <span class="c"># TODO: Is there a clever way to globally set the hyperprior?</span>
    <span class="c"># @hyperprior.setter</span>
    <span class="c"># def hyperprior(self, value):</span>
    <span class="c">#     pass</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">fixed_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">fixed_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">fixed_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">fp</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">fixed_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fp</span>
    
    <span class="nd">@fixed_params.setter</span>
<div class="viewcode-block" id="GaussianProcess.fixed_params"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.fixed_params">[docs]</a>    <span class="k">def</span> <span class="nf">fixed_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">fixed_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">fixed_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">fixed_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:]</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="nd">@params.setter</span>
<div class="viewcode-block" id="GaussianProcess.params"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.params">[docs]</a>    <span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:]</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">param_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="o">.</span><span class="n">bounds</span>
    
    <span class="nd">@param_bounds.setter</span>
<div class="viewcode-block" id="GaussianProcess.param_bounds"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.param_bounds">[docs]</a>    <span class="k">def</span> <span class="nf">param_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">value</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pn</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">param_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">param_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">pn</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">pn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">param_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pn</span>
    
    <span class="nd">@param_names.setter</span>
<div class="viewcode-block" id="GaussianProcess.param_names"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.param_names">[docs]</a>    <span class="k">def</span> <span class="nf">param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_params</span><span class="p">:]</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">free_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="nd">@free_params.setter</span>
<div class="viewcode-block" id="GaussianProcess.free_params"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.free_params">[docs]</a>    <span class="k">def</span> <span class="nf">free_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the free parameters. Note that this bypasses enforce_bounds.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_params</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:]</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">free_param_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fpb</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_param_bounds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_param_bounds</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">fpb</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">fpb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_param_bounds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fpb</span>
    
    <span class="nd">@free_param_bounds.setter</span>
<div class="viewcode-block" id="GaussianProcess.free_param_bounds"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.free_param_bounds">[docs]</a>    <span class="k">def</span> <span class="nf">free_param_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_param_bounds</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_param_bounds</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_param_bounds</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:]</span>
    </div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">free_param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">CombinedBounds</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="nd">@free_param_names.setter</span>
<div class="viewcode-block" id="GaussianProcess.free_param_names"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.free_param_names">[docs]</a>    <span class="k">def</span> <span class="nf">free_param_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">free_param_names</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_free_params</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">num_free_params</span><span class="p">:]</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.add_data"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.add_data">[docs]</a>    <span class="k">def</span> <span class="nf">add_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">err_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>   
        <span class="sd">&quot;&quot;&quot;Add data to the training data set of the GaussianProcess instance.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, (`M`, `D`)</span>
<span class="sd">            `M` input values of dimension `D`.</span>
<span class="sd">        y : array, (`M`,)</span>
<span class="sd">            `M` target values.</span>
<span class="sd">        err_y : array, (`M`,) or scalar float, optional</span>
<span class="sd">            Non-negative values only. Error given as standard deviation) in the</span>
<span class="sd">            `M` target values. If `err_y` is a scalar, the data set is taken to</span>
<span class="sd">            be homoscedastic (constant error). Otherwise, the length of `err_y`</span>
<span class="sd">            must equal the length of `y`. Default value is 0 (noiseless</span>
<span class="sd">            observations).</span>
<span class="sd">        n : array, (`M`, `D`) or scalar float, optional</span>
<span class="sd">            Non-negative integer values only. Degree of derivative for each</span>
<span class="sd">            target. If `n` is a scalar it is taken to be the value for all</span>
<span class="sd">            points in `y`. Otherwise, the length of n must equal the length of</span>
<span class="sd">            `y`. Default value is 0 (observation of target value). If</span>
<span class="sd">            non-integer values are passed, they will be silently rounded.</span>
<span class="sd">        T : array, (`M`, `N`), optional</span>
<span class="sd">            Linear transformation to get from latent variables to data in the</span>
<span class="sd">            argument `y`. When `T` is passed the argument `y` holds the</span>
<span class="sd">            transformed quantities `y=TY(X)` where `y` are the observed values</span>
<span class="sd">            of the transformed quantities, `T` is the transformation matrix and</span>
<span class="sd">            `Y(X)` is the underlying (untransformed) values of the function to</span>
<span class="sd">            be fit that enter into the transformation. When `T` is `M`-by-`N`</span>
<span class="sd">            and `y` has `M` elements, `X` and `n` will both be `N`-by-`D`.</span>
<span class="sd">            Default is None (no transformation).</span>
<span class="sd">        </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            Bad shapes for any of the inputs, negative values for `err_y` or `n`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># Verify y has only one non-trivial dimension:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Training targets y must have only one &quot;</span>
                                 <span class="s">&quot;dimension with length greater than one! Shape &quot;</span>
                                 <span class="s">&quot;of y given is </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,))</span>
        
        <span class="c"># Handle scalar error or verify shape of array error matches shape of y:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">err_y</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">err_y</span> <span class="o">=</span> <span class="n">err_y</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">err_y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">err_y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">err_y</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;When using array-like err_y, shape must match &quot;</span>
                                 <span class="s">&quot;shape of y! Shape of err_y given is </span><span class="si">%s</span><span class="s">, shape &quot;</span>
                                 <span class="s">&quot;of y given is </span><span class="si">%s</span><span class="s">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">err_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">err_y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;All elements of err_y must be non-negative!&quot;</span><span class="p">)</span>
        
        <span class="c"># Handle scalar training input or convert array input into 2d.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
        <span class="c"># Correct single-dimension inputs:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Shape of training inputs must be (len(y), &quot;</span>
                             <span class="s">&quot;k.num_dim)! X given has shape </span><span class="si">%s</span><span class="s">, shape of y is &quot;</span>
                             <span class="s">&quot;</span><span class="si">%s</span><span class="s"> and num_dim=</span><span class="si">%d</span><span class="s">.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span><span class="p">))</span>
        
        <span class="c"># Handle scalar derivative orders or verify shape of array derivative</span>
        <span class="c"># orders matches shape of y:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
            <span class="c"># Correct single-dimension inputs:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;When using array-like n, shape must be &quot;</span>
                                 <span class="s">&quot;(len(y), k.num_dim)! Shape of n given is </span><span class="si">%s</span><span class="s">, &quot;</span>
                                 <span class="s">&quot;shape of y given is </span><span class="si">%s</span><span class="s"> and num_dim=</span><span class="si">%d</span><span class="s">.&quot;</span>
                                 <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;All elements of n must be non-negative integers!&quot;</span><span class="p">)</span>
        
        <span class="c"># Handle transform:</span>
        <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">T</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;T must have exactly 2 dimensions!&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s">&quot;T must have as many rows are there are elements in y!&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s">&quot;There must be as many columns in T as there are rows in X!&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span>
            
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">block_diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err_y</span><span class="p">,</span> <span class="n">err_y</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.condense_duplicates"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.condense_duplicates">[docs]</a>    <span class="k">def</span> <span class="nf">condense_duplicates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Condense duplicate points using a transformation matrix.</span>
<span class="sd">        </span>
<span class="sd">        This is useful if you have multiple non-transformed points at the same</span>
<span class="sd">        location or multiple transformed points that use the same quadrature</span>
<span class="sd">        points.</span>
<span class="sd">        </span>
<span class="sd">        Won&#39;t change the GP if all of the rows of [X, n] are unique. Will create</span>
<span class="sd">        a transformation matrix T if necessary. Note that the order of the</span>
<span class="sd">        points in [X, n] will be arbitrary after this operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">unique</span><span class="p">,</span> <span class="n">inv</span> <span class="o">=</span> <span class="n">unique_rows</span><span class="p">(</span>
            <span class="n">scipy</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)),</span>
            <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="c"># Only proceed if there is anything to be gained:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span>
            <span class="n">new_T</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),</span> <span class="n">unique</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inv</span><span class="p">)):</span>
                <span class="n">new_T</span><span class="p">[:,</span> <span class="n">inv</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">new_T</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">unique</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">unique</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.remove_outliers"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.remove_outliers">[docs]</a>    <span class="k">def</span> <span class="nf">remove_outliers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="o">**</span><span class="n">predict_kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Remove outliers from the GP.</span>
<span class="sd">        </span>
<span class="sd">        Removes points that are more than `thresh` * `err_y` away from the GP</span>
<span class="sd">        mean. Note that this is only very rough in that it ignores the</span>
<span class="sd">        uncertainty in the GP mean at any given point. But you should only be</span>
<span class="sd">        using this as a rough way of removing bad channels, anyways!</span>
<span class="sd">        </span>
<span class="sd">        Returns the values that were removed and a boolean array indicating</span>
<span class="sd">        where the removed points were.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        thresh : float, optional</span>
<span class="sd">            The threshold as a multiplier times `err_y`. Default is 3 (i.e.,</span>
<span class="sd">            throw away all 3-sigma points).</span>
<span class="sd">        **predict_kwargs : optional kwargs</span>
<span class="sd">            All additional kwargs are passed to :py:meth:`predict`. You can, for</span>
<span class="sd">            instance, use this to make it use MCMC to evaluate the mean. (If you</span>
<span class="sd">            don&#39;t use MCMC, then the current value of the hyperparameters is</span>
<span class="sd">            used.)</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_bad : array</span>
<span class="sd">            Input values of the bad points.</span>
<span class="sd">        y_bad : array</span>
<span class="sd">            Bad values.</span>
<span class="sd">        err_y_bad : array</span>
<span class="sd">            Uncertainties on the bad values.</span>
<span class="sd">        n_bad : array</span>
<span class="sd">            Derivative order of the bad values.</span>
<span class="sd">        bad_idxs : array</span>
<span class="sd">            Array of booleans with the original shape of X with True wherever</span>
<span class="sd">            a point was taken to be bad and subsequently removed.</span>
<span class="sd">        T_bad : array</span>
<span class="sd">            Transformation matrix of returned points. Only returned if</span>
<span class="sd">            :py:attr:`T` is not None for the instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># Find where a point lies more than thresh*err_y away from the mean:</span>
        <span class="c"># This is naive as it does not account for the posterior variance in the</span>
        <span class="c"># GP itself, but should work as a first-cut approach to deleting</span>
        <span class="c"># outliers.</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">output_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="o">**</span><span class="n">predict_kwargs</span>
        <span class="p">)</span>
        <span class="n">deltas</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span>
        <span class="n">deltas</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">err_y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">bad_idxs</span> <span class="o">=</span> <span class="p">(</span><span class="n">deltas</span> <span class="o">&gt;=</span> <span class="n">thresh</span><span class="p">)</span>
        <span class="n">good_idxs</span> <span class="o">=</span> <span class="o">~</span><span class="n">bad_idxs</span>
        
        <span class="c"># Pull out the old values so they can be returned:</span>
        <span class="n">y_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">bad_idxs</span><span class="p">]</span>
        <span class="n">err_y_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span><span class="p">[</span><span class="n">bad_idxs</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">T_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="n">bad_idxs</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">non_zero_cols</span> <span class="o">=</span> <span class="p">(</span><span class="n">T_bad</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">T_bad</span> <span class="o">=</span> <span class="n">T_bad</span><span class="p">[:,</span> <span class="n">non_zero_cols</span><span class="p">]</span>
            <span class="n">X_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">non_zero_cols</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">n_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">[</span><span class="n">non_zero_cols</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">bad_idxs</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">n_bad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">[</span><span class="n">bad_idxs</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="c"># Delete the offending points:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">good_idxs</span><span class="p">,</span> <span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">[</span><span class="n">good_idxs</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="n">good_idxs</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">non_zero_cols</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="n">non_zero_cols</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">non_zero_cols</span><span class="p">,</span> <span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">[</span><span class="n">non_zero_cols</span><span class="p">,</span> <span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">good_idxs</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span><span class="p">[</span><span class="n">good_idxs</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">X_bad</span><span class="p">,</span> <span class="n">y_bad</span><span class="p">,</span> <span class="n">err_y_bad</span><span class="p">,</span> <span class="n">n_bad</span><span class="p">,</span> <span class="n">bad_idxs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">X_bad</span><span class="p">,</span> <span class="n">y_bad</span><span class="p">,</span> <span class="n">err_y_bad</span><span class="p">,</span> <span class="n">n_bad</span><span class="p">,</span> <span class="n">bad_idxs</span><span class="p">,</span> <span class="n">T_bad</span><span class="p">)</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.optimize_hyperparameters"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.optimize_hyperparameters">[docs]</a>    <span class="k">def</span> <span class="nf">optimize_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="o">=</span><span class="p">{},</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_starts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;Optimize the hyperparameters by maximizing the log likelihood.</span>
<span class="sd">        </span>
<span class="sd">        Leaves the :py:class:`GaussianProcess` instance in the optimized state.</span>
<span class="sd">        </span>
<span class="sd">        If :py:func:`scipy.optimize.minimize` is not available (i.e., if your</span>
<span class="sd">        :py:mod:`scipy` version is older than 0.11.0) then :py:func:`fmin_slsqp`</span>
<span class="sd">        is used independent of what you set for the `method` keyword.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        method : str, optional</span>
<span class="sd">            The method to pass to :py:func:`scipy.optimize.minimize`.</span>
<span class="sd">            Refer to that function&#39;s docstring for valid options. Default</span>
<span class="sd">            is &#39;SLSQP&#39;. See note above about behavior with older versions of</span>
<span class="sd">            :py:mod:`scipy`.</span>
<span class="sd">        opt_kwargs : dict, optional</span>
<span class="sd">            Dictionary of extra keywords to pass to</span>
<span class="sd">            :py:func:`scipy.optimize.minimize`. Refer to that function&#39;s</span>
<span class="sd">            docstring for valid options. Note that if you use `jac` = True (i.e.,</span>
<span class="sd">            optimization function returns Jacobian) you should also set `args`</span>
<span class="sd">            = (True,) to tell :py:meth:`update_hyperparameters` to compute and</span>
<span class="sd">            return the Jacobian. Default is: {}.</span>
<span class="sd">        verbose : bool, optional</span>
<span class="sd">            Whether or not the output should be verbose. If True, the entire</span>
<span class="sd">            :py:class:`Result` object from :py:func:`scipy.optimize.minimize` is</span>
<span class="sd">            printed. If False, status information is only printed if the</span>
<span class="sd">            `success` flag from :py:func:`minimize` is False. Default is False.</span>
<span class="sd">        random_starts : non-negative int, optional</span>
<span class="sd">            Number of times to randomly perturb the starting guesses</span>
<span class="sd">            (distributed uniformly within their bounds) in order to seek the</span>
<span class="sd">            global minimum. If None, then `num_proc` random starts will be</span>
<span class="sd">            performed. Default is None (do number of random starts equal to the</span>
<span class="sd">            number of processors allocated). Note that for `random_starts` != 0,</span>
<span class="sd">            the initial guesses provided are not actually used.</span>
<span class="sd">        num_proc : non-negative int or None</span>
<span class="sd">            Number of processors to use with random starts. If 0, processing is</span>
<span class="sd">            not done in parallel. If None, all available processors are used.</span>
<span class="sd">            Default is None (use all available processors).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">opt_kwargs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">opt_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">opt_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="s">&#39;method&#39;</span> <span class="ow">in</span> <span class="n">opt_kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s">&quot;Key &#39;method&#39; is present in opt_kwargs, will override option &quot;</span>
                <span class="s">&quot;specified with method kwarg.&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt_kwargs</span><span class="p">[</span><span class="s">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">method</span>
        
        <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
        
        <span class="n">param_ranges</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_param_bounds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="c"># Replace unbounded variables with something big:</span>
        <span class="n">param_ranges</span><span class="p">[</span><span class="n">scipy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">param_ranges</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])),</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1e16</span>
        <span class="n">param_ranges</span><span class="p">[</span><span class="n">scipy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">param_ranges</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])),</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e16</span>
        <span class="k">if</span> <span class="n">random_starts</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">param_samples</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">free_params</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">random_starts</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">random_starts</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_proc</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c"># Distribute random guesses according to the hyperprior:</span>
            <span class="n">param_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="o">.</span><span class="n">random_draw</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">random_starts</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="n">param_samples</span> <span class="o">=</span> <span class="n">param_samples</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">fixed_params</span><span class="p">]</span>
        <span class="k">if</span> <span class="s">&#39;bounds&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opt_kwargs</span><span class="p">:</span>
            <span class="n">opt_kwargs</span><span class="p">[</span><span class="s">&#39;bounds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_ranges</span>
        <span class="k">if</span> <span class="n">num_proc</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">samp</span> <span class="ow">in</span> <span class="n">param_samples</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="p">[</span>
                        <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">,</span>
                            <span class="n">samp</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">opt_kwargs</span>
                        <span class="p">)</span>
                    <span class="p">]</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s">&quot;scipy.optimize.minimize not available, defaulting to &quot;</span>
                        <span class="s">&quot;fmin_slsqp.&quot;</span><span class="p">,</span>
                        <span class="ne">RuntimeWarning</span>
                    <span class="p">)</span>
                    <span class="n">res</span> <span class="o">+=</span> <span class="p">[</span>
                        <span class="n">wrap_fmin_slsqp</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">,</span>
                            <span class="n">samp</span><span class="p">,</span>
                            <span class="n">opt_kwargs</span><span class="o">=</span><span class="n">opt_kwargs</span>
                        <span class="p">)</span>
                    <span class="p">]</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s">&quot;Minimizer failed, skipping sample. Error is: </span><span class="si">%s</span><span class="s">: </span><span class="si">%s</span><span class="s">. &quot;</span>
                        <span class="s">&quot;State of params is: </span><span class="si">%s</span><span class="s"> </span><span class="si">%s</span><span class="s">&quot;</span>
                        <span class="o">%</span> <span class="p">(</span>
                            <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
                            <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">),</span>
                            <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span>
                        <span class="p">),</span>
                        <span class="ne">RuntimeWarning</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">num_proc</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="n">_OptimizeHyperparametersEval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="p">),</span>
                    <span class="n">param_samples</span>
                <span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="c"># Filter out the failed convergences:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">res_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">fun</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s">&quot;Optimizer failed to find a valid solution. Try changing the &quot;</span>
                <span class="s">&quot;parameter bounds, picking a new initial guess or increasing the &quot;</span>
                <span class="s">&quot;number of random starts.&quot;</span>
            <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span><span class="n">res_min</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">&quot;Got </span><span class="si">%d</span><span class="s"> completed starts, optimal result is:&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">),))</span>
            <span class="k">print</span><span class="p">(</span><span class="n">res_min</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">LL</span><span class="se">\t</span><span class="si">%.3g</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">res_min</span><span class="o">.</span><span class="n">fun</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">res_min</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">):</span>
                <span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%.3g</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s">&#39;</span><span class="se">\\</span><span class="s">&#39;</span><span class="p">),</span> <span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">res_min</span><span class="o">.</span><span class="n">success</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s">&quot;Optimizer </span><span class="si">%s</span><span class="s"> reports failure, selected hyperparameters are &quot;</span>
                <span class="s">&quot;likely NOT optimal. Status: </span><span class="si">%d</span><span class="s">, Message: &#39;</span><span class="si">%s</span><span class="s">&#39;. Try adjusting &quot;</span>
                <span class="s">&quot;bounds, initial guesses or the number of random starts used.&quot;</span>
                <span class="o">%</span> <span class="p">(</span>
                    <span class="n">method</span><span class="p">,</span>
                    <span class="n">res_min</span><span class="o">.</span><span class="n">status</span><span class="p">,</span>
                    <span class="n">res_min</span><span class="o">.</span><span class="n">message</span>
                <span class="p">),</span>
                <span class="ne">RuntimeWarning</span>
            <span class="p">)</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_param_bounds</span><span class="p">)</span>
        <span class="c"># Augment the bounds a little bit to catch things that are one step away:</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">res_min</span><span class="o">.</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mf">1.001</span> <span class="o">*</span> <span class="n">bounds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span>
            <span class="p">(</span><span class="n">res_min</span><span class="o">.</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mf">0.999</span> <span class="o">*</span> <span class="n">bounds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">any</span><span class="p">()):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s">&quot;Optimizer appears to have hit/exceeded the bounds. Bounds are:</span><span class="se">\n</span><span class="s">&quot;</span>
                <span class="s">&quot;</span><span class="si">%s</span><span class="se">\n</span><span class="s">, solution is:</span><span class="se">\n</span><span class="si">%s</span><span class="s">. Try adjusting bounds, initial guesses &quot;</span>
                <span class="s">&quot;or the number of random starts used.&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">bounds</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">res_min</span><span class="o">.</span><span class="n">x</span><span class="p">),)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">res_min</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">))</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.predict"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xstar</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                <span class="n">full_output</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_samples</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">samp_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">use_MCMC</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">full_MC</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">rejection_func</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the mean and covariance at the inputs `Xstar`.</span>
<span class="sd">        </span>
<span class="sd">        The order of the derivative is given by `n`. The keyword `noise` sets</span>
<span class="sd">        whether or not noise is included in the prediction.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xstar : array, (`M`, `D`)</span>
<span class="sd">            `M` test input values of dimension `D`.</span>
<span class="sd">        n : array, (`M`, `D`) or scalar, non-negative int, optional</span>
<span class="sd">            Order of derivative to predict (0 is the base quantity). If `n` is</span>
<span class="sd">            scalar, the value is used for all points in `Xstar`. If non-integer</span>
<span class="sd">            values are passed, they will be silently rounded. Default is 0</span>
<span class="sd">            (return base quantity).</span>
<span class="sd">        noise : bool, optional</span>
<span class="sd">            Whether or not noise should be included in the covariance. Default</span>
<span class="sd">            is False (no noise in covariance).</span>
<span class="sd">        return_std : bool, optional</span>
<span class="sd">            Set to True to compute and return the standard deviation for the</span>
<span class="sd">            predictions, False to skip this step. Default is True (return tuple</span>
<span class="sd">            of (`mean`, `std`)).</span>
<span class="sd">        return_cov : bool, optional</span>
<span class="sd">            Set to True to compute and return the full covariance matrix for the</span>
<span class="sd">            predictions. This overrides the `return_std` keyword. If you want</span>
<span class="sd">            both the standard deviation and covariance matrix pre-computed, use</span>
<span class="sd">            the `full_output` keyword.</span>
<span class="sd">        full_output : bool, optional</span>
<span class="sd">            Set to True to return the full outputs in a dictionary with keys:</span>
<span class="sd">            </span>
<span class="sd">                ==== ==========================================================================</span>
<span class="sd">                mean mean of GP at requested points</span>
<span class="sd">                std  standard deviation of GP at requested points</span>
<span class="sd">                cov  covariance matrix for values of GP at requested points</span>
<span class="sd">                samp random samples of GP at requested points (only if `return_sample` is True)</span>
<span class="sd">                ==== ==========================================================================</span>
<span class="sd">        </span>
<span class="sd">        return_samples : bool, optional</span>
<span class="sd">            Set to True to compute and return samples of the GP in addition to</span>
<span class="sd">            computing the mean. Only done if `full_output` is True. Default is</span>
<span class="sd">            False.</span>
<span class="sd">        num_samples : int, optional</span>
<span class="sd">            Number of samples to compute. If using MCMC this is the number of</span>
<span class="sd">            samples per MCMC sample, if using present values of hyperparameters</span>
<span class="sd">            this is the number of samples actually returned. Default is 1.</span>
<span class="sd">        samp_kwargs : dict, optional</span>
<span class="sd">            Additional keywords to pass to :py:meth:`draw_sample` if</span>
<span class="sd">            `return_samples` is True. Default is {}.</span>
<span class="sd">        use_MCMC : bool, optional</span>
<span class="sd">            Set to True to use :py:meth:`predict_MCMC` to evaluate the prediction</span>
<span class="sd">            marginalized over the hyperparameters.</span>
<span class="sd">        full_MC : bool, optional</span>
<span class="sd">            Set to True to compute the mean and covariance matrix using Monte</span>
<span class="sd">            Carlo sampling of the posterior. The samples will also be returned</span>
<span class="sd">            if full_output is True. Default is False (don&#39;t use full sampling).</span>
<span class="sd">        rejection_func : callable, optional</span>
<span class="sd">            Any samples where this function evaluates False will be rejected,</span>
<span class="sd">            where it evaluates True they will be kept. Default is None (no</span>
<span class="sd">            rejection). Only has an effect if `full_MC` is True.</span>
<span class="sd">        ddof : int, optional</span>
<span class="sd">            The degree of freedom correction to use when computing the covariance</span>
<span class="sd">            matrix when `full_MC` is True. Default is 1 (unbiased estimator).</span>
<span class="sd">        output_transform: array, (`L`, `M`), optional</span>
<span class="sd">            Matrix to use to transform the output vector of length `M` to one of</span>
<span class="sd">            length `L`. This can, for instance, be used to compute integrals.</span>
<span class="sd">        **kwargs : optional kwargs</span>
<span class="sd">            All additional kwargs are passed to :py:meth:`predict_MCMC` if</span>
<span class="sd">            `use_MCMC` is True.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mean : array, (`M`,)</span>
<span class="sd">            Predicted GP mean. Only returned if `full_output` is False.</span>
<span class="sd">        std : array, (`M`,)</span>
<span class="sd">            Predicted standard deviation, only returned if `return_std` is True, `return_cov` is False and `full_output` is False.</span>
<span class="sd">        cov : array, (`M`, `M`)</span>
<span class="sd">            Predicted covariance matrix, only returned if `return_cov` is True and `full_output` is False.</span>
<span class="sd">        full_output : dict</span>
<span class="sd">            Dictionary with fields for mean, std, cov and possibly random samples. Only returned if `full_output` is True.</span>
<span class="sd">        </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `n` is not consistent with the shape of `Xstar` or is not entirely</span>
<span class="sd">            composed of non-negative integers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">use_MCMC</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_MCMC</span><span class="p">(</span>
                <span class="n">Xstar</span><span class="p">,</span>
                <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span>
                <span class="n">return_std</span><span class="o">=</span><span class="n">return_std</span> <span class="ow">or</span> <span class="n">full_output</span><span class="p">,</span>
                <span class="n">return_cov</span><span class="o">=</span><span class="n">return_cov</span> <span class="ow">or</span> <span class="n">full_output</span><span class="p">,</span>
                <span class="n">return_samples</span><span class="o">=</span><span class="n">full_output</span> <span class="ow">and</span> <span class="p">(</span><span class="n">return_samples</span> <span class="ow">or</span> <span class="n">rejection_func</span><span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
                <span class="n">samp_kwargs</span><span class="o">=</span><span class="n">samp_kwargs</span><span class="p">,</span>
                <span class="n">full_MC</span><span class="o">=</span><span class="n">full_MC</span><span class="p">,</span>
                <span class="n">rejection_func</span><span class="o">=</span><span class="n">rejection_func</span><span class="p">,</span>
                <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span>
                <span class="n">output_transform</span><span class="o">=</span><span class="n">output_transform</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">res</span>
            <span class="k">elif</span> <span class="n">return_cov</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">return_std</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">res</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Process Xstar:</span>
            <span class="n">Xstar</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xstar</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
            <span class="c"># Handle 1d x case where array is passed in:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">Xstar</span> <span class="o">=</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s">&quot;Second dimension of Xstar must be equal to self.num_dim! &quot;</span>
                    <span class="s">&quot;Shape of Xstar given is </span><span class="si">%s</span><span class="s">, num_dim is </span><span class="si">%d</span><span class="s">.&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
                <span class="p">)</span>
            
            <span class="c"># Process T:</span>
            <span class="k">if</span> <span class="n">output_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">output_transform</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">output_transform</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">output_transform</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s">&quot;output_transform must have exactly 2 dimensions! Shape &quot;</span>
                        <span class="s">&quot;of output_transform given is </span><span class="si">%s</span><span class="s">.&quot;</span>
                        <span class="o">%</span> <span class="p">(</span><span class="n">output_transform</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="n">output_transform</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s">&quot;output_transform must have the same number of columns &quot;</span>
                        <span class="s">&quot;the number of rows in Xstar! Shape of output_transform &quot;</span>
                        <span class="s">&quot;given is </span><span class="si">%s</span><span class="s">, shape of Xstar is </span><span class="si">%s</span><span class="s">.&quot;</span>
                        <span class="o">%</span> <span class="p">(</span><span class="n">output_transform</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span>
                    <span class="p">)</span>
            
            <span class="c"># Process n:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">iter</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">T</span>
                <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s">&quot;When using array-like n, shape must match shape of Xstar! &quot;</span>
                        <span class="s">&quot;Shape of n given is </span><span class="si">%s</span><span class="s">, shape of Xstar given is </span><span class="si">%s</span><span class="s">.&quot;</span>
                        <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xstar</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;All elements of n must be non-negative integers!&quot;</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_K_L_alpha_ll</span><span class="p">()</span>
            <span class="n">Kstar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">Xstar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">noise</span><span class="p">:</span>
                <span class="n">Kstar</span> <span class="o">=</span> <span class="n">Kstar</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">Xstar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">Kstar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Kstar</span><span class="p">)</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">Kstar</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">mean</span> <span class="o">+=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">(</span><span class="n">Xstar</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">output_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">mean</span> <span class="o">=</span> <span class="n">output_transform</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span> <span class="ow">or</span> <span class="n">full_output</span> <span class="ow">or</span> <span class="n">full_MC</span><span class="p">:</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="n">Kstar</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                <span class="n">Kstarstar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="n">Xstar</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">noise</span><span class="p">:</span>
                    <span class="n">Kstarstar</span> <span class="o">=</span> <span class="n">Kstarstar</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="n">Xstar</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
                <span class="n">covariance</span> <span class="o">=</span> <span class="n">Kstarstar</span> <span class="o">-</span> <span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">output_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">covariance</span> <span class="o">=</span> <span class="n">output_transform</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">covariance</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">output_transform</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">return_samples</span> <span class="ow">or</span> <span class="n">full_MC</span><span class="p">:</span>
                    <span class="n">samps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">draw_sample</span><span class="p">(</span>
                        <span class="n">Xstar</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">num_samp</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">covariance</span><span class="p">,</span> <span class="o">**</span><span class="n">samp_kwargs</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">rejection_func</span><span class="p">:</span>
                        <span class="n">good_samps</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">samp</span> <span class="ow">in</span> <span class="n">samps</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">rejection_func</span><span class="p">(</span><span class="n">samp</span><span class="p">):</span>
                                <span class="n">good_samps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">good_samps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Did not get any good samples!&quot;</span><span class="p">)</span>
                        <span class="n">samps</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">good_samps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
                    <span class="k">if</span> <span class="n">full_MC</span><span class="p">:</span>
                        <span class="n">mean</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">covariance</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
                <span class="n">std</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">covariance</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s">&#39;mean&#39;</span><span class="p">:</span> <span class="n">mean</span><span class="p">,</span>
                        <span class="s">&#39;std&#39;</span><span class="p">:</span> <span class="n">std</span><span class="p">,</span>
                        <span class="s">&#39;cov&#39;</span><span class="p">:</span> <span class="n">covariance</span>
                    <span class="p">}</span>
                    <span class="k">if</span> <span class="n">return_samples</span> <span class="ow">or</span> <span class="n">full_MC</span><span class="p">:</span>
                        <span class="n">out</span><span class="p">[</span><span class="s">&#39;samp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samps</span>
                    <span class="k">return</span> <span class="n">out</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">return_std</span><span class="p">:</span>
                        <span class="k">return</span> <span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">mean</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">mean</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.plot"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.plot">[docs]</a>    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">envelopes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">base_alpha</span><span class="o">=</span><span class="mf">0.375</span><span class="p">,</span>
             <span class="n">return_prediction</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
             <span class="n">plot_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Plots the Gaussian process using the current hyperparameters. Only for num_dim &lt;= 2.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (`M`,) or (`M`, `num_dim`), optional</span>
<span class="sd">            The values to evaluate the Gaussian process at. If None, then 100</span>
<span class="sd">            points between the minimum and maximum of the data&#39;s X are used.</span>
<span class="sd">            Default is None (use 100 points between min and max).</span>
<span class="sd">        n : int or list, optional</span>
<span class="sd">            The order of derivative to compute. For num_dim=1, this must be an</span>
<span class="sd">            int. For num_dim=2, this must be a list of ints of length 2.</span>
<span class="sd">            Default is 0 (don&#39;t take derivative).</span>
<span class="sd">        ax : axis instance, optional</span>
<span class="sd">            Axis to plot the result on. If no axis is passed, one is created.</span>
<span class="sd">            If the string &#39;gca&#39; is passed, the current axis (from plt.gca())</span>
<span class="sd">            is used. If X_dim = 2, the axis must be 3d.</span>
<span class="sd">        envelopes: list of float, optional</span>
<span class="sd">            +/-n*sigma envelopes to plot. Default is [1, 3].</span>
<span class="sd">        base_alpha : float, optional</span>
<span class="sd">            Alpha value to use for +/-1*sigma envelope. All other envelopes env</span>
<span class="sd">            are drawn with base_alpha/env. Default is 0.375.</span>
<span class="sd">        return_prediction : bool, optional</span>
<span class="sd">            If True, the predicted values are also returned. Default is False.</span>
<span class="sd">        return_std : bool, optional</span>
<span class="sd">            If True, the standard deviation is computed and returned along with</span>
<span class="sd">            the mean when `return_prediction` is True. Default is True.</span>
<span class="sd">        full_output : bool, optional</span>
<span class="sd">            Set to True to return the full outputs in a dictionary with keys:</span>
<span class="sd">            </span>
<span class="sd">                ==== ==========================================================================</span>
<span class="sd">                mean mean of GP at requested points</span>
<span class="sd">                std  standard deviation of GP at requested points</span>
<span class="sd">                cov  covariance matrix for values of GP at requested points</span>
<span class="sd">                samp random samples of GP at requested points (only if `return_sample` is True)</span>
<span class="sd">                ==== ==========================================================================</span>
<span class="sd">            </span>
<span class="sd">        plot_kwargs : dict, optional</span>
<span class="sd">            The entries in this dictionary are passed as kwargs to the plotting</span>
<span class="sd">            command used to plot the mean. Use this to, for instance, change the</span>
<span class="sd">            color, line width and line style.</span>
<span class="sd">        **kwargs : extra arguments for predict, optional</span>
<span class="sd">            Extra arguments that are passed to :py:meth:`predict`.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ax : axis instance</span>
<span class="sd">            The axis instance used.</span>
<span class="sd">        mean : :py:class:`Array`, (`M`,)</span>
<span class="sd">            Predicted GP mean. Only returned if `return_prediction` is True and `full_output` is False.</span>
<span class="sd">        std : :py:class:`Array`, (`M`,)</span>
<span class="sd">            Predicted standard deviation, only returned if `return_prediction` and `return_std` are True and `full_output` is False.</span>
<span class="sd">        full_output : dict</span>
<span class="sd">            Dictionary with fields for mean, std, cov and possibly random samples. Only returned if `return_prediction` and `full_output` are True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Plotting is not supported for num_dim &gt; 2!&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">x1</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">50</span><span class="p">)</span>
                <span class="n">x2</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">50</span><span class="p">)</span>
                <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
                <span class="n">X1</span> <span class="o">=</span> <span class="n">X1</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="n">X2</span> <span class="o">=</span> <span class="n">X2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X1</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
                <span class="n">X2</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">envelopes</span> <span class="ow">or</span> <span class="p">(</span><span class="n">return_prediction</span> <span class="ow">and</span> <span class="p">(</span><span class="n">return_std</span> <span class="ow">or</span> <span class="n">full_output</span><span class="p">)):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">univariate_envelope_plot</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">mean</span><span class="p">,</span>
                <span class="n">std</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                <span class="n">base_alpha</span><span class="o">=</span><span class="n">base_alpha</span><span class="p">,</span>
                <span class="n">envelopes</span><span class="o">=</span><span class="n">envelopes</span><span class="p">,</span>
                <span class="o">**</span><span class="n">plot_kwargs</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">&#39;3d&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">ax</span> <span class="o">==</span> <span class="s">&#39;gca&#39;</span><span class="p">:</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            <span class="k">if</span> <span class="s">&#39;linewidths&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;linewidths&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">envelopes</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">base_alpha</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">base_alpha</span> <span class="o">/</span> <span class="n">i</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">base_alpha</span> <span class="o">/</span> <span class="n">i</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">return_prediction</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">full_output</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">return_std</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ax</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.draw_sample"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.draw_sample">[docs]</a>    <span class="k">def</span> <span class="nf">draw_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xstar</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_samp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rand_vars</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">rand_type</span><span class="o">=</span><span class="s">&#39;standard normal&#39;</span><span class="p">,</span> <span class="n">diag_factor</span><span class="o">=</span><span class="mf">1e3</span><span class="p">,</span>
                    <span class="n">method</span><span class="o">=</span><span class="s">&#39;cholesky&#39;</span><span class="p">,</span> <span class="n">num_eig</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Draw a sample evaluated at the given points `Xstar`.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xstar : array, (`M`, `D`)</span>
<span class="sd">            `M` test input values of dimension `D`.</span>
<span class="sd">        n : array, (`M`, `D`) or scalar, non-negative int, optional</span>
<span class="sd">            Derivative order to evaluate at. Default is 0 (evaluate value).</span>
<span class="sd">        noise : bool, optional</span>
<span class="sd">            Whether or not to include the noise components of the kernel in the</span>
<span class="sd">            sample. Default is False (no noise in samples).</span>
<span class="sd">        num_samp : Positive int, optional</span>
<span class="sd">            Number of samples to draw. Default is 1. Cannot be used in</span>
<span class="sd">            conjunction with `rand_vars`: If you pass both `num_samp` and</span>
<span class="sd">            `rand_vars`, `num_samp` will be silently ignored.</span>
<span class="sd">        rand_vars : array, (`M`, `P`), optional</span>
<span class="sd">            Vector of random variables :math:`u` to use in constructing the</span>
<span class="sd">            sample :math:`y_* = f_* + Lu`, where :math:`K=LL^T`. If None,</span>
<span class="sd">            values will be produced using</span>
<span class="sd">            :py:func:`numpy.random.multivariate_normal`. This allows you to use</span>
<span class="sd">            pseudo/quasi random numbers generated by an external routine.</span>
<span class="sd">            Default is None (use :py:func:`multivariate_normal` directly).</span>
<span class="sd">        rand_type : {&#39;standard normal&#39;, &#39;uniform&#39;}, optional</span>
<span class="sd">            Type of distribution the inputs are given with.</span>
<span class="sd">            </span>
<span class="sd">                * &#39;standard normal&#39;: Standard (`mu` = 0, `sigma` = 1) normal</span>
<span class="sd">                  distribution (this is the default)</span>
<span class="sd">                * &#39;uniform&#39;: Uniform distribution on [0, 1). In this case</span>
<span class="sd">                  the required Gaussian variables are produced with inversion.</span>
<span class="sd">                  </span>
<span class="sd">        diag_factor : float, optional</span>
<span class="sd">            Number (times machine epsilon) added to the diagonal of the</span>
<span class="sd">            covariance matrix prior to computing its Cholesky decomposition.</span>
<span class="sd">            This is necessary as sometimes the decomposition will fail because,</span>
<span class="sd">            to machine precision, the matrix appears to not be positive definite.</span>
<span class="sd">            If you are getting errors from :py:func:`scipy.linalg.cholesky`, try</span>
<span class="sd">            increasing this an order of magnitude at a time. This parameter only</span>
<span class="sd">            has an effect when using rand_vars. Default value is 1e3. </span>
<span class="sd">        method : {&#39;cholesky&#39;, &#39;eig&#39;}, optional</span>
<span class="sd">            Method to use for constructing the matrix square root. Default is</span>
<span class="sd">            &#39;cholesky&#39; (use lower-triangular Cholesky decomposition).</span>
<span class="sd">            </span>
<span class="sd">                * &#39;cholesky&#39;: Perform Cholesky decomposition on the covariance</span>
<span class="sd">                  matrix: :math:`K=LL^T`, use :math:`L` as the matrix square</span>
<span class="sd">                  root.</span>
<span class="sd">                * &#39;eig&#39;: Perform an eigenvalue decomposition on the covariance</span>
<span class="sd">                  matrix: :math:`K=Q \\Lambda Q^{-1}`, use :math:`Q\\Lambda^{1/2}`</span>
<span class="sd">                  as the matrix square root.</span>
<span class="sd">        </span>
<span class="sd">        num_eig : int or None, optional</span>
<span class="sd">            Number of eigenvalues to compute. Can range from 1 to `M` (the</span>
<span class="sd">            number of test points). If it is None, then all eigenvalues are</span>
<span class="sd">            computed. Default is None (compute all eigenvalues). This keyword</span>
<span class="sd">            only has an effect if `method` is &#39;eig&#39;.</span>
<span class="sd">        mean : array, (`M`,)</span>
<span class="sd">            If you have pre-computed the mean and covariance matrix, then you</span>
<span class="sd">            can simply pass them in with the `mean` and `cov` keywords to save</span>
<span class="sd">            on having to call :py:meth:`predict`.</span>
<span class="sd">        cov : array, (`M`, `M`)</span>
<span class="sd">            If you have pre-computed the mean and covariance matrix, then you</span>
<span class="sd">            can simply pass them in with the `mean` and `cov` keywords to save</span>
<span class="sd">            on having to call :py:meth:`predict`.</span>
<span class="sd">        **kwargs : optional kwargs</span>
<span class="sd">            All extra keyword arguments are passed to :py:meth:`predict` when</span>
<span class="sd">            evaluating the mean and covariance matrix of the GP.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        samples : :py:class:`Array` (`M`, `P`) or (`M`, `num_samp`)</span>
<span class="sd">            Samples evaluated at the `M` points.</span>
<span class="sd">        </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If rand_type or method is invalid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># All of the input processing for Xstar and n will be done in here:</span>
        <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">cov</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xstar</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">full_output</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">rand_vars</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">method</span> <span class="o">!=</span> <span class="s">&#39;eig&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">num_samp</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="k">except</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s">&quot;Failure when drawing from MVN! Falling back on eig. &quot;</span>
                    <span class="s">&quot;Exception was:</span><span class="se">\n</span><span class="si">%s</span><span class="s">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">e</span><span class="p">,),</span>
                    <span class="ne">RuntimeWarning</span>
                <span class="p">)</span>
                <span class="n">method</span> <span class="o">=</span> <span class="s">&#39;eig&#39;</span>
        
        <span class="k">if</span> <span class="n">num_eig</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">num_eig</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean</span><span class="p">):</span>
            <span class="n">num_eig</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">num_eig</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">num_eig</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">rand_vars</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">rand_vars</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">num_eig</span><span class="p">,</span> <span class="n">num_samp</span><span class="p">))</span>
        <span class="n">valid_types</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;standard normal&#39;</span><span class="p">,</span> <span class="s">&#39;uniform&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rand_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;rand_type </span><span class="si">%s</span><span class="s"> not recognized! Valid options &quot;</span>
                             <span class="s">&quot;are: </span><span class="si">%s</span><span class="s">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">rand_type</span><span class="p">,</span> <span class="n">valid_types</span><span class="p">,))</span>
        <span class="k">if</span> <span class="n">rand_type</span> <span class="o">==</span> <span class="s">&#39;uniform&#39;</span><span class="p">:</span>
            <span class="n">rand_vars</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">rand_vars</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;cholesky&#39;</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span>
                <span class="n">cov</span> <span class="o">+</span> <span class="n">diag_factor</span> <span class="o">*</span> <span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">check_finite</span><span class="o">=</span><span class="bp">False</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;eig&#39;</span><span class="p">:</span>
            <span class="c"># TODO: Add support for specifying cutoff eigenvalue!</span>
            <span class="c"># Not technically lower triangular, but we&#39;ll keep the name L:</span>
            <span class="n">eig</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span>
                <span class="n">cov</span> <span class="o">+</span> <span class="n">diag_factor</span> <span class="o">*</span> <span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">eigvals</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">num_eig</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">Lam_1_2</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">eig</span><span class="p">))</span>
            <span class="n">L</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Lam_1_2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;method </span><span class="si">%s</span><span class="s"> not recognized!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">method</span><span class="p">,))</span>
        <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">L</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rand_vars</span><span class="p">[:</span><span class="n">num_eig</span><span class="p">,</span> <span class="p">:])</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.update_hyperparameters"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.update_hyperparameters">[docs]</a>    <span class="k">def</span> <span class="nf">update_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_params</span><span class="p">,</span> <span class="n">exit_on_bounds</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inf_on_error</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the kernel&#39;s hyperparameters to the new parameters.</span>
<span class="sd">        </span>
<span class="sd">        This will call :py:meth:`compute_K_L_alpha_ll` to update the state</span>
<span class="sd">        accordingly.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_params : :py:class:`Array` or other Array-like, length dictated by kernel</span>
<span class="sd">            New parameters to use.</span>
<span class="sd">        exit_on_bounds : bool, optional</span>
<span class="sd">            If True, the method will automatically exit if the hyperparameters</span>
<span class="sd">            are impossible given the hyperprior, without trying to update the</span>
<span class="sd">            internal state. This is useful during MCMC sampling and optimization.</span>
<span class="sd">            Default is True (don&#39;t perform update for impossible hyperparameters).</span>
<span class="sd">        inf_on_error : bool, optional</span>
<span class="sd">            If True, the method will return `scipy.inf` if the hyperparameters</span>
<span class="sd">            produce a linear algebra error upon trying to update the Gaussian</span>
<span class="sd">            process. Default is True (catch errors and return infinity).</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        -1*ll : float</span>
<span class="sd">            The updated log likelihood.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">set_hyperparams</span><span class="p">(</span><span class="n">new_params</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">set_hyperparams</span><span class="p">(</span>
            <span class="n">new_params</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">):</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">set_hyperparams</span><span class="p">(</span>
                <span class="n">new_params</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span><span class="p">):]</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">exit_on_bounds</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">scipy</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)):</span>
                <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_K_L_alpha_ll</span><span class="p">()</span>
        <span class="k">except</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">inf_on_error</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s">&quot;Failure when updating GP! Exception was:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s">&quot;</span>
                    <span class="s">&quot;State of params is: </span><span class="si">%s</span><span class="s">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span>
                        <span class="n">e</span><span class="p">,</span>
                        <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_params</span><span class="p">[:]),</span>
                    <span class="p">),</span>
                    <span class="ne">RuntimeWarning</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">inf</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">inf_on_error</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s">&quot;Unhandled exception! Exception was:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s">&quot;</span>
                    <span class="s">&quot;State of params is: </span><span class="si">%s</span><span class="s">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span>
                    <span class="n">e</span><span class="p">,</span>
                    <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_params</span><span class="p">[:]))</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">inf</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ll</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.compute_K_L_alpha_ll"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.compute_K_L_alpha_ll">[docs]</a>    <span class="k">def</span> <span class="nf">compute_K_L_alpha_ll</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;Compute `K`, `L`, `alpha` and log-likelihood according to the first part of Algorithm 2.1 in R&amp;W.</span>
<span class="sd">        </span>
<span class="sd">        Computes `K` and the noise portion of `K` using :py:meth:`compute_Kij`,</span>
<span class="sd">        computes `L` using :py:func:`scipy.linalg.cholesky`, then computes</span>
<span class="sd">        `alpha` as `L.T\\(L\\y)`.</span>
<span class="sd">        </span>
<span class="sd">        Only does the computation if :py:attr:`K_up_to_date` is False --</span>
<span class="sd">        otherwise leaves the existing values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
            <span class="n">err_y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">err_y</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_Kij</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>
            <span class="n">noise_K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_K</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">noise_K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">noise_K</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">K_tot</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">K</span> <span class="o">+</span>
                <span class="n">scipy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">err_y</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">+</span>
                <span class="n">noise_K</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">diag_factor</span> <span class="o">*</span> <span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_tot</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="c"># Need to make the mean-subtracted y that appears in the expression</span>
            <span class="c"># for alpha:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">mu_alph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">mu_alph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mu_alph</span><span class="p">)</span>
                <span class="n">y_alph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu_alph</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_alph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span>
                    <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">y_alph</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                    <span class="n">lower</span><span class="o">=</span><span class="bp">True</span>
                <span class="p">),</span>
                <span class="n">lower</span><span class="o">=</span><span class="bp">False</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ll</span> <span class="o">=</span> <span class="p">(</span>
                <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">y_alph</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">-</span>
                <span class="n">scipy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> 
                <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="c"># Apply hyperpriors:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ll</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">K_up_to_date</span> <span class="o">=</span> <span class="bp">True</span>
    </div>
    <span class="nd">@property</span>
<div class="viewcode-block" id="GaussianProcess.num_dim"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.num_dim">[docs]</a>    <span class="k">def</span> <span class="nf">num_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The number of dimensions of the input data.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        num_dim: int</span>
<span class="sd">            The number of dimensions of the input data as defined in the kernel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">num_dim</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.compute_Kij"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.compute_Kij">[docs]</a>    <span class="k">def</span> <span class="nf">compute_Kij</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xi</span><span class="p">,</span> <span class="n">Xj</span><span class="p">,</span> <span class="n">ni</span><span class="p">,</span> <span class="n">nj</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">hyper_deriv</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;Compute covariance matrix between datasets `Xi` and `Xj`.</span>
<span class="sd">        </span>
<span class="sd">        Specify the orders of derivatives at each location with the `ni`, `nj`</span>
<span class="sd">        arrays. The `include_noise` flag is passed to the covariance kernel to</span>
<span class="sd">        indicate whether noise is to be included (i.e., for evaluation of</span>
<span class="sd">        :math:`K+\sigma I` versus :math:`K_*`).</span>
<span class="sd">        </span>
<span class="sd">        If `Xj` is None, the symmetric matrix :math:`K(X, X)` is formed.</span>
<span class="sd">        </span>
<span class="sd">        Note that type and dimension checking is NOT performed, as it is assumed</span>
<span class="sd">        the data are from inside the instance and have hence been sanitized by</span>
<span class="sd">        :py:meth:`add_data`.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xi : array, (`M`, `D`)</span>
<span class="sd">            `M` input values of dimension `D`.</span>
<span class="sd">        Xj : array, (`P`, `D`)</span>
<span class="sd">            `P` input values of dimension `D`.</span>
<span class="sd">        ni : array, (`M`,), non-negative integers</span>
<span class="sd">            `M` derivative orders with respect to the `Xi` coordinates.</span>
<span class="sd">        nj : array, (`P`,), non-negative integers</span>
<span class="sd">            `P` derivative orders with respect to the `Xj` coordinates.</span>
<span class="sd">        noise : bool, optional</span>
<span class="sd">            If True, uses the noise kernel, otherwise uses the regular kernel.</span>
<span class="sd">            Default is False (use regular kernel).</span>
<span class="sd">        hyper_deriv : None or non-negative int</span>
<span class="sd">            Index of the hyperparameter to compute the first derivative with</span>
<span class="sd">            respect to. If None, no derivatives are taken. Default is None (no</span>
<span class="sd">            hyperparameter derivatives).</span>
<span class="sd">                </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Kij : array, (`M`, `P`)</span>
<span class="sd">            Covariance matrix between `Xi` and `Xj`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">noise</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span>
        
        <span class="k">if</span> <span class="n">Xj</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">symmetric</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="n">Xj</span> <span class="o">=</span> <span class="n">Xi</span>
            <span class="n">nj</span> <span class="o">=</span> <span class="n">ni</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">symmetric</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="c"># This technically doesn&#39;t take advantage of the symmetric case. Might</span>
        <span class="c"># be worth trying to do that at some point, but this is vastly superior</span>
        <span class="c"># to the double for loop implementation for which using symmetry is easy.</span>
        <span class="n">Xi_tile</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">Xi</span><span class="p">,</span> <span class="n">Xj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ni_tile</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">Xj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Xj_tile</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">Xj</span><span class="p">,</span> <span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">nj_tile</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">nj</span><span class="p">,</span> <span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">Kij</span> <span class="o">=</span> <span class="n">k</span><span class="p">(</span>
            <span class="n">Xi_tile</span><span class="p">,</span>
            <span class="n">Xj_tile</span><span class="p">,</span>
            <span class="n">ni_tile</span><span class="p">,</span>
            <span class="n">nj_tile</span><span class="p">,</span>
            <span class="n">hyper_deriv</span><span class="o">=</span><span class="n">hyper_deriv</span><span class="p">,</span>
            <span class="n">symmetric</span><span class="o">=</span><span class="n">symmetric</span>
        <span class="p">)</span>
        <span class="n">Kij</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Kij</span><span class="p">,</span> <span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">Kij</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.compute_ll_matrix"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.compute_ll_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">compute_ll_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">num_pts</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the log likelihood over the (free) parameter space.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bounds : 2-tuple or list of 2-tuples with length equal to the number of free parameters</span>
<span class="sd">            Bounds on the range to use for each of the parameters. If a single</span>
<span class="sd">            2-tuple is given, it will be used for each of the parameters.</span>
<span class="sd">        num_pts : int or list of ints with length equal to the number of free parameters</span>
<span class="sd">            If a single int is given, it will be used for each of the parameters.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            ll_vals : :py:class:`Array`</span>
<span class="sd">                The log likelihood for each of the parameter possibilities.</span>
<span class="sd">            param_vals : List of :py:class:`Array`</span>
<span class="sd">                The parameter values used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">present_free_params</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">free_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_k</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Argument bounds must have shape (n, 2)!&quot;</span><span class="p">)</span>
        <span class="c"># If bounds is a single tuple, repeat it for each free parameter:</span>
        <span class="k">if</span> <span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">present_free_params</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c"># If num_pts is a single value, use it for all of the parameters:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">num_pts</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">num_pts</span> <span class="o">=</span> <span class="n">num_pts</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_pts</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">num_pts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">num_pts</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">present_free_params</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Length of num_pts must match the number of &quot;</span>
                                 <span class="s">&quot;free parameters of kernel!&quot;</span><span class="p">)</span>
        
        <span class="c"># Form arrays to evaluate parameters over:</span>
        <span class="n">param_vals</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">present_free_params</span><span class="p">)):</span>
            <span class="n">param_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">num_pts</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
        <span class="n">ll_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ll_matrix</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">param_vals</span><span class="p">,</span> <span class="n">num_pts</span><span class="p">)</span>
        
        <span class="c"># Reset the parameters to what they were before:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">present_free_params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="p">(</span><span class="n">ll_vals</span><span class="p">,</span> <span class="n">param_vals</span><span class="p">)</span>
    </div>
    <span class="k">def</span> <span class="nf">_compute_ll_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param_vals</span><span class="p">,</span> <span class="n">num_pts</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Recursive helper function for compute_ll_matrix.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        idx : int</span>
<span class="sd">            The index of the parameter for this layer of the recursion to</span>
<span class="sd">            work on. `idx` == len(`num_pts`) is the base case that terminates</span>
<span class="sd">            the recursion.</span>
<span class="sd">        param_vals : List of :py:class:`Array`</span>
<span class="sd">            List of arrays of parameter values. Entries in the slots 0:`idx` are</span>
<span class="sd">            set to scalars by the previous levels of recursion.</span>
<span class="sd">        num_pts : :py:class:`Array`</span>
<span class="sd">            The numbers of points for each parameter.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        vals : :py:class:`Array`</span>
<span class="sd">            The log likelihood for each of the parameter possibilities at lower</span>
<span class="sd">            levels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">num_pts</span><span class="p">):</span>
            <span class="c"># Base case: All entries in param_vals should be scalars:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span>
                <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">param_vals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Recursive case: call _compute_ll_matrix for each entry in param_vals[idx]:</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_pts</span><span class="p">[</span><span class="n">idx</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_vals</span><span class="p">[</span><span class="n">idx</span><span class="p">])):</span>
                <span class="n">specific_param_vals</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">param_vals</span><span class="p">)</span>
                <span class="n">specific_param_vals</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_vals</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>
                <span class="n">vals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_ll_matrix</span><span class="p">(</span>
                    <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">specific_param_vals</span><span class="p">,</span>
                    <span class="n">num_pts</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">vals</span>
    
<div class="viewcode-block" id="GaussianProcess.sample_hyperparameter_posterior"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.sample_hyperparameter_posterior">[docs]</a>    <span class="k">def</span> <span class="nf">sample_hyperparameter_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nwalkers</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">nsamp</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">burn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                        <span class="n">thin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_proc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                        <span class="n">plot_posterior</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                        <span class="n">plot_chains</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">sampler_type</span><span class="o">=</span><span class="s">&#39;ensemble&#39;</span><span class="p">,</span>
                                        <span class="n">ntemps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">sampler_a</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Produce samples from the posterior for the hyperparameters using MCMC.</span>
<span class="sd">        </span>
<span class="sd">        Returns the sampler created, because storing it stops the GP from being</span>
<span class="sd">        pickleable. To add more samples to a previous sampler, pass the sampler</span>
<span class="sd">        instance in the `sampler` keyword.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nwalkers : int, optional</span>
<span class="sd">            The number of walkers to use in the sampler. Should be on the order</span>
<span class="sd">            of several hundred. Default is 200.</span>
<span class="sd">        nsamp : int, optional</span>
<span class="sd">            Number of samples (per walker) to take. Default is 500.</span>
<span class="sd">        burn : int, optional</span>
<span class="sd">            This keyword only has an effect on the corner plot produced when</span>
<span class="sd">            `plot_posterior` is True and the flattened chain plot produced</span>
<span class="sd">            when `plot_chains` is True. To perform computations with burn-in,</span>
<span class="sd">            see :py:meth:`compute_from_MCMC`. The number of samples to discard</span>
<span class="sd">            at the beginning of the chain. Default is 0.</span>
<span class="sd">        thin : int, optional</span>
<span class="sd">            This keyword only has an effect on the corner plot produced when</span>
<span class="sd">            `plot_posterior` is True and the flattened chain plot produced</span>
<span class="sd">            when `plot_chains` is True. To perform computations with thinning,</span>
<span class="sd">            see :py:meth:`compute_from_MCMC`. Every `thin`-th sample is kept.</span>
<span class="sd">            Default is 1.</span>
<span class="sd">        num_proc : int or None, optional</span>
<span class="sd">            Number of processors to use. If None, all available processors are</span>
<span class="sd">            used. Default is None (use all available processors).</span>
<span class="sd">        sampler : :py:class:`Sampler` instance</span>
<span class="sd">            The sampler to use. If the sampler already has samples, the most</span>
<span class="sd">            recent sample will be used as the starting point. Otherwise a</span>
<span class="sd">            random sample from the hyperprior will be used.</span>
<span class="sd">        plot_posterior : bool, optional</span>
<span class="sd">            If True, a corner plot of the posterior for the hyperparameters</span>
<span class="sd">            will be generated. Default is False.</span>
<span class="sd">        plot_chains : bool, optional</span>
<span class="sd">            If True, a plot showing the history and autocorrelation of the</span>
<span class="sd">            chains will be produced.</span>
<span class="sd">        sampler_type : str, optional</span>
<span class="sd">            The type of sampler to use. Valid options are &quot;ensemble&quot; (affine-</span>
<span class="sd">            invariant ensemble sampler) and &quot;pt&quot; (parallel-tempered ensemble</span>
<span class="sd">            sampler).</span>
<span class="sd">        ntemps : int, optional</span>
<span class="sd">            Number of temperatures to use with the parallel-tempered ensemble</span>
<span class="sd">            sampler.</span>
<span class="sd">        sampler_a : float, optional</span>
<span class="sd">            Scale of the proposal distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_proc</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
        <span class="c"># Needed for emcee to do it right:</span>
        <span class="k">if</span> <span class="n">num_proc</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_proc</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sampler_type</span> <span class="o">==</span> <span class="s">&#39;ensemble&#39;</span><span class="p">:</span>
                <span class="n">sampler</span> <span class="o">=</span> <span class="n">emcee</span><span class="o">.</span><span class="n">EnsembleSampler</span><span class="p">(</span>
                    <span class="n">nwalkers</span><span class="p">,</span>
                    <span class="n">ndim</span><span class="p">,</span>
                    <span class="n">_ComputeLnProbEval</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
                    <span class="n">threads</span><span class="o">=</span><span class="n">num_proc</span><span class="p">,</span>
                    <span class="n">a</span><span class="o">=</span><span class="n">sampler_a</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">sampler_type</span> <span class="o">==</span> <span class="s">&#39;pt&#39;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s">&quot;PTSampler not done yet!&quot;</span><span class="p">)</span>
                <span class="n">sampler</span> <span class="o">=</span> <span class="n">emcee</span><span class="o">.</span><span class="n">PTSampler</span><span class="p">(</span>
                    <span class="n">ntemps</span><span class="p">,</span>
                    <span class="n">nwalkers</span><span class="p">,</span>
                    <span class="n">ndim</span><span class="p">,</span>
                    <span class="n">logl</span><span class="p">,</span>
                    <span class="n">logp</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s">&quot;Sampler type </span><span class="si">%s</span><span class="s"> not supported!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sampler_type</span><span class="p">,)</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">theta0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperprior</span><span class="o">.</span><span class="n">random_draw</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">nwalkers</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="n">theta0</span> <span class="o">=</span> <span class="n">theta0</span><span class="p">[:,</span> <span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">fixed_params</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Start from the stopping point of the previous chain:</span>
            <span class="n">theta0</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">sampler</span><span class="o">.</span><span class="n">run_mcmc</span><span class="p">(</span><span class="n">theta0</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">plot_posterior</span> <span class="ow">or</span> <span class="n">plot_chains</span><span class="p">:</span>
            <span class="n">flat_trace</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span> <span class="n">burn</span><span class="p">::</span><span class="n">thin</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">flat_trace</span> <span class="o">=</span> <span class="n">flat_trace</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">flat_trace</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        
        <span class="k">if</span> <span class="n">plot_posterior</span> <span class="ow">and</span> <span class="n">plot_chains</span><span class="p">:</span>
            <span class="n">plot_sampler</span><span class="p">(</span>
                <span class="n">sampler</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;$</span><span class="si">%s</span><span class="s">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">l</span><span class="p">,)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">],</span>
                <span class="n">burn</span><span class="o">=</span><span class="n">burn</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">plot_posterior</span><span class="p">:</span>
                <span class="n">triangle</span><span class="o">.</span><span class="n">corner</span><span class="p">(</span>
                    <span class="n">flat_trace</span><span class="p">,</span>
                    <span class="n">plot_datapoints</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;$</span><span class="si">%s</span><span class="s">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">l</span><span class="p">,)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">plot_chains</span><span class="p">:</span>
                <span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ndim</span><span class="p">):</span>
                    <span class="c"># a = f.add_subplot(3, ndim, k + 1)</span>
                    <span class="c"># a.acorr(</span>
                    <span class="c">#     sampler.flatchain[:, k],</span>
                    <span class="c">#     maxlags=100,</span>
                    <span class="c">#     detrend=plt.mlab.detrend_mean</span>
                    <span class="c"># )</span>
                    <span class="c"># a.set_xlabel(&#39;lag&#39;)</span>
                    <span class="c"># a.set_title(&#39;$%s$ autocorrelation&#39; % (self.free_param_names[k],))</span>
                    <span class="n">a</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">ndim</span> <span class="o">+</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">]:</span>
                        <span class="n">a</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
                    <span class="n">a</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">&#39;sample&#39;</span><span class="p">)</span>
                    <span class="n">a</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">&#39;$</span><span class="si">%s</span><span class="s">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">[</span><span class="n">k</span><span class="p">],))</span>
                    <span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&#39;$</span><span class="si">%s</span><span class="s">$ all chains&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">free_param_names</span><span class="p">[</span><span class="n">k</span><span class="p">],))</span>
                    <span class="n">a</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">burn</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">&#39;--&#39;</span><span class="p">)</span>
                    <span class="c"># a = f.add_subplot(2, ndim, 1 * ndim + k + 1)</span>
                    <span class="c"># a.plot(flat_trace[:, k])</span>
                    <span class="c"># a.set_xlabel(&#39;sample&#39;)</span>
                    <span class="c"># a.set_ylabel(&#39;$%s$&#39; % (self.free_param_names[k],))</span>
                    <span class="c"># a.set_title(&#39;$%s$ flattened, burned and thinned chain&#39; % (self.free_param_names[k],))</span>
            
        <span class="k">return</span> <span class="n">sampler</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.compute_from_MCMC"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.compute_from_MCMC">[docs]</a>    <span class="k">def</span> <span class="nf">compute_from_MCMC</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_mean</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                          <span class="n">return_cov</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_samples</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">noise</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">samp_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                          <span class="n">flat_trace</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">burn</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute desired quantities from MCMC samples of the hyperparameter posterior.</span>
<span class="sd">        </span>
<span class="sd">        The return will be a list with a number of rows equal to the number of</span>
<span class="sd">        hyperparameter samples. The columns depend on the state of the boolean</span>
<span class="sd">        flags, but will be some subset of (mean, stddev, cov, samples), in that</span>
<span class="sd">        order. Samples will be the raw output of :py:meth:`draw_sample`, so you</span>
<span class="sd">        will need to remember to convert to an array and flatten if you want to</span>
<span class="sd">        work with a single sample.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (`M`,) or (`M`, `num_dim`)</span>
<span class="sd">            The values to evaluate the Gaussian process at.</span>
<span class="sd">        n : non-negative int or list, optional</span>
<span class="sd">            The order of derivative to compute. For num_dim=1, this must be an</span>
<span class="sd">            int. For num_dim=2, this must be a list of ints of length 2.</span>
<span class="sd">            Default is 0 (don&#39;t take derivative).</span>
<span class="sd">        return_mean : bool, optional</span>
<span class="sd">            If True, the mean will be computed at each hyperparameter sample.</span>
<span class="sd">            Default is True (compute mean).</span>
<span class="sd">        return_std : bool, optional</span>
<span class="sd">            If True, the standard deviation will be computed at each</span>
<span class="sd">            hyperparameter sample. Default is True (compute stddev).</span>
<span class="sd">        return_cov : bool, optional</span>
<span class="sd">            If True, the covariance matrix will be computed at each</span>
<span class="sd">            hyperparameter sample. Default is True (compute stddev).</span>
<span class="sd">        return_samples : bool, optional</span>
<span class="sd">            If True, random sample(s) will be computed at each hyperparameter</span>
<span class="sd">            sample. Default is False (do not compute samples).</span>
<span class="sd">        num_samples : int, optional</span>
<span class="sd">            Compute this many samples if `return_sample` is True. Default is 1.</span>
<span class="sd">        noise : bool, optional</span>
<span class="sd">            If True, noise is included in the predictions and samples. Default</span>
<span class="sd">            is False (do not include noise).</span>
<span class="sd">        samp_kwargs : dict, optional</span>
<span class="sd">            If `return_sample` is True, the contents of this dictionary will be</span>
<span class="sd">            passed as kwargs to :py:meth:`draw_sample`.</span>
<span class="sd">        sampler : :py:class:`Sampler` instance or None, optional</span>
<span class="sd">            :py:class:`Sampler` instance that has already been run to the extent</span>
<span class="sd">            desired on the hyperparameter posterior. If None, a new sampler will</span>
<span class="sd">            be created with :py:meth:`sample_hyperparameter_posterior`. In this</span>
<span class="sd">            case, all extra kwargs will be passed on, allowing you to set the</span>
<span class="sd">            number of samples, etc. Default is None (create sampler).</span>
<span class="sd">        flat_trace : array-like (`nsamp`, `ndim`) or None, optional</span>
<span class="sd">            Flattened trace with samples of the free hyperparameters. If present,</span>
<span class="sd">            overrides `sampler`. This allows you to use a sampler other than the</span>
<span class="sd">            ones from :py:mod:`emcee`, or to specify arbitrary values you wish</span>
<span class="sd">            to evaluate the curve at. Note that this WILL be thinned and burned</span>
<span class="sd">            according to the following two kwargs. &quot;Flat&quot; refers to the fact</span>
<span class="sd">            that you must have combined all chains into a single one. Default is</span>
<span class="sd">            None (use `sampler`).</span>
<span class="sd">        burn : int, optional</span>
<span class="sd">            The number of samples to discard at the beginning of the chain.</span>
<span class="sd">            Default is 0.</span>
<span class="sd">        thin : int, optional</span>
<span class="sd">            Every `thin`-th sample is kept. Default is 1.</span>
<span class="sd">        num_proc : int, optional</span>
<span class="sd">            The number of processors to use for evaluation. This is used both</span>
<span class="sd">            when calling the sampler and when evaluating the Gaussian process.</span>
<span class="sd">            If None, the number of available processors will be used. If zero,</span>
<span class="sd">            evaluation will proceed in parallel. Default is to use all available</span>
<span class="sd">            processors.</span>
<span class="sd">        **kwargs : extra optional kwargs</span>
<span class="sd">            All additional kwargs are passed to</span>
<span class="sd">            :py:meth:`sample_hyperparameter_posterior`.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : dict</span>
<span class="sd">            A dictionary having some or all of the fields &#39;mean&#39;, &#39;std&#39;, &#39;cov&#39;</span>
<span class="sd">            and &#39;samp&#39;. Each entry is a list of array-like. The length of this</span>
<span class="sd">            list is equal to the number of hyperparameter samples used, and the</span>
<span class="sd">            entries have the following shapes:</span>
<span class="sd">            </span>
<span class="sd">                ==== ====================</span>
<span class="sd">                mean (`M`,)</span>
<span class="sd">                std  (`M`,)</span>
<span class="sd">                cov  (`M`, `M`)</span>
<span class="sd">                samp (`M`, `num_samples`)</span>
<span class="sd">                ==== ====================</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_transform</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;output_transform&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">flat_trace</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">sampler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_hyperparameter_posterior</span><span class="p">(</span><span class="n">burn</span><span class="o">=</span><span class="n">burn</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="c"># If we create the sampler, we need to make sure we clean up its pool:</span>
                <span class="n">sampler</span><span class="o">.</span><span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                
            <span class="n">flat_trace</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">chain</span><span class="p">[:,</span> <span class="n">burn</span><span class="p">::</span><span class="n">thin</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">flat_trace</span> <span class="o">=</span> <span class="n">flat_trace</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">flat_trace</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">flat_trace</span> <span class="o">=</span> <span class="n">flat_trace</span><span class="p">[</span><span class="n">burn</span><span class="p">::</span><span class="n">thin</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="n">num_proc</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;num_proc&#39;</span><span class="p">,</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">())</span>
        
        <span class="k">if</span> <span class="n">num_proc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">pool</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">num_proc</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
                    <span class="n">_ComputeGPWrapper</span><span class="p">(</span>
                        <span class="bp">self</span><span class="p">,</span>
                        <span class="n">X</span><span class="p">,</span>
                        <span class="n">n</span><span class="p">,</span>
                        <span class="n">return_mean</span><span class="p">,</span>
                        <span class="n">return_std</span><span class="p">,</span>
                        <span class="n">return_cov</span><span class="p">,</span>
                        <span class="n">return_samples</span><span class="p">,</span>
                        <span class="n">num_samples</span><span class="p">,</span>
                        <span class="n">noise</span><span class="p">,</span>
                        <span class="n">samp_kwargs</span><span class="p">,</span>
                        <span class="n">output_transform</span>
                    <span class="p">),</span>
                    <span class="n">flat_trace</span>
                <span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span>
                <span class="n">_ComputeGPWrapper</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="n">X</span><span class="p">,</span>
                    <span class="n">n</span><span class="p">,</span>
                    <span class="n">return_mean</span><span class="p">,</span>
                    <span class="n">return_std</span><span class="p">,</span>
                    <span class="n">return_cov</span><span class="p">,</span>
                    <span class="n">return_samples</span><span class="p">,</span>
                    <span class="n">num_samples</span><span class="p">,</span>
                    <span class="n">noise</span><span class="p">,</span>
                    <span class="n">samp_kwargs</span><span class="p">,</span>
                    <span class="n">output_transform</span>
                    <span class="p">),</span>
                    <span class="n">flat_trace</span>
                <span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">return_mean</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">return_samples</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;samp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s">&#39;samp&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">res</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">out</span>
    </div>
<div class="viewcode-block" id="GaussianProcess.predict_MCMC"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.GaussianProcess.predict_MCMC">[docs]</a>    <span class="k">def</span> <span class="nf">predict_MCMC</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">full_MC</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">rejection_func</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Make a prediction using MCMC samples.</span>
<span class="sd">        </span>
<span class="sd">        This is essentially a convenient wrapper of :py:meth:`compute_from_MCMC`,</span>
<span class="sd">        designed to act more or less interchangeably with :py:meth:`predict`.</span>
<span class="sd">        </span>
<span class="sd">        Computes the mean of the GP posterior marginalized over the</span>
<span class="sd">        hyperparameters using iterated expectations. If `return_std` is True,</span>
<span class="sd">        uses the law of total variance to compute the variance of the GP</span>
<span class="sd">        posterior marginalized over the hyperparameters. If `return_cov` is True,</span>
<span class="sd">        uses the law of total covariance to compute the entire covariance of the</span>
<span class="sd">        GP posterior marginalized over the hyperparameters. If both `return_cov`</span>
<span class="sd">        and `return_std` are True, then both the covariance matrix and standard</span>
<span class="sd">        deviation array will be returned.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like (`M`,) or (`M`, `num_dim`)</span>
<span class="sd">            The values to evaluate the Gaussian process at.</span>
<span class="sd">        ddof : int, optional</span>
<span class="sd">            The degree of freedom correction to use when computing the variance.</span>
<span class="sd">            Default is 1 (standard Bessel correction for unbiased estimate).</span>
<span class="sd">        return_std : bool, optional</span>
<span class="sd">            If True, the standard deviation is also computed. Default is True.</span>
<span class="sd">        full_MC : bool, optional</span>
<span class="sd">            Set to True to compute the mean and covariance matrix using Monte</span>
<span class="sd">            Carlo sampling of the posterior. The samples will also be returned</span>
<span class="sd">            if full_output is True. Default is False (don&#39;t use full sampling).</span>
<span class="sd">        rejection_func : callable, optional</span>
<span class="sd">            Any samples where this function evaluates False will be rejected,</span>
<span class="sd">            where it evaluates True they will be kept. Default is None (no</span>
<span class="sd">            rejection). Only has an effect if `full_MC` is True.</span>
<span class="sd">        ddof : int, optional</span>
<span class="sd">        **kwargs : optional kwargs</span>
<span class="sd">            All additional kwargs are passed directly to</span>
<span class="sd">            :py:meth:`compute_from_MCMC`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">return_std</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;return_std&#39;</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">return_cov</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;return_cov&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">full_MC</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;return_mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;return_std&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;return_cov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;return_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;return_mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="n">return_samples</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;return_samples&#39;</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_from_MCMC</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">if</span> <span class="n">return_samples</span><span class="p">:</span>
            <span class="n">samps</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;samp&#39;</span><span class="p">]))</span>
        
        <span class="k">if</span> <span class="n">full_MC</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rejection_func</span><span class="p">:</span>
                <span class="n">good_samps</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">samp</span> <span class="ow">in</span> <span class="n">samps</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">rejection_func</span><span class="p">(</span><span class="n">samp</span><span class="p">):</span>
                        <span class="n">good_samps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">good_samps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Did not get any good samples!&quot;</span><span class="p">)</span>
                <span class="n">samps</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">good_samps</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">samps</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">means</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">])</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="s">&#39;cov&#39;</span> <span class="ow">in</span> <span class="n">res</span><span class="p">:</span>
                <span class="n">covs</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">])</span>
                <span class="n">cov</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">covs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">scipy</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
                <span class="n">std</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>
            <span class="k">elif</span> <span class="s">&#39;std&#39;</span> <span class="ow">in</span> <span class="n">res</span><span class="p">:</span>
                <span class="n">vars_</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">]))</span><span class="o">**</span><span class="mi">2</span>
                <span class="n">std</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">vars_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span>
                                 <span class="n">scipy</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">))</span>
        
        <span class="n">out</span><span class="p">[</span><span class="s">&#39;mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="k">if</span> <span class="n">return_samples</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;samp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samps</span>
        <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;std&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s">&#39;cov&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cov</span>
        
        <span class="k">return</span> <span class="n">out</span>
</div></div>
<span class="k">class</span> <span class="nc">_ComputeGPWrapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper to allow parallel evaluation of means, covariances and random draws.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gp : :py:class:`GaussianProcess` instance</span>
<span class="sd">        The :py:class:`GaussianProcess` to wrap.</span>
<span class="sd">    X : array-like</span>
<span class="sd">        The evaluation locations to use. No pre-processing is performed: `X`</span>
<span class="sd">        will be passed directly to :py:meth:`predict` and/or :py:meth:`draw_sample`.</span>
<span class="sd">    n : int or array-like</span>
<span class="sd">        The derivative orders to use. No pre-processing is performed: `n` will</span>
<span class="sd">        be passed directly to :py:meth:`predict` and/or :py:meth:`draw_sample`.</span>
<span class="sd">    return_mean : bool</span>
<span class="sd">        If True, the mean will be computed.</span>
<span class="sd">    return_std : bool</span>
<span class="sd">        If True, the standard deviation will be computed.</span>
<span class="sd">    return_cov : bool</span>
<span class="sd">        If True, the covariance matrix will be computed.</span>
<span class="sd">    return_sample : bool</span>
<span class="sd">        If True, random sample(s) will be computed.</span>
<span class="sd">    num_samples : int</span>
<span class="sd">        If `return_sample` is True, this many random samples will be computed.</span>
<span class="sd">    noise : bool</span>
<span class="sd">        If True, noise will be included in the prediction and samples.</span>
<span class="sd">    samp_kwargs : dict</span>
<span class="sd">        The contents of this dictionary will be passed to :py:meth:`draw_sample`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">return_mean</span><span class="p">,</span> <span class="n">return_std</span><span class="p">,</span> <span class="n">return_cov</span><span class="p">,</span>
                 <span class="n">return_sample</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">samp_kwargs</span><span class="p">,</span> <span class="n">output_transform</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">gp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_mean</span> <span class="o">=</span> <span class="n">return_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_std</span> <span class="o">=</span> <span class="n">return_std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_cov</span> <span class="o">=</span> <span class="n">return_cov</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_sample</span> <span class="o">=</span> <span class="n">return_sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samp_kwargs</span> <span class="o">=</span> <span class="n">samp_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">full_output</span> <span class="o">=</span> <span class="n">return_cov</span> <span class="ow">or</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span> <span class="o">=</span> <span class="n">output_transform</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_case</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate the desired quantities with free hyperparameters `p_case`.</span>
<span class="sd">        </span>
<span class="sd">        Returns a dict with some or all of the fields &#39;mean&#39;, &#39;cov&#39;, &#39;std&#39;, &#39;samp&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">p_case</span><span class="p">))</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
                <span class="n">noise</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">,</span>
                <span class="n">full_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_output</span><span class="p">,</span>
                <span class="n">return_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_sample</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
                <span class="n">output_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_output</span><span class="p">:</span>
                <span class="c"># If full output is True, return_mean must be the only True thing,</span>
                <span class="c"># since otherwise this isn&#39;t computing anything!</span>
                <span class="k">return</span> <span class="p">{</span><span class="s">&#39;mean&#39;</span><span class="p">:</span> <span class="n">out</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_mean</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;mean&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_std</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;std&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_cov</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">&#39;cov&#39;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s">&quot;Encountered exception during evaluation of MCMC samples. &quot;</span>
                <span class="s">&quot;Exception is:</span><span class="se">\n</span><span class="si">%s</span><span class="se">\n</span><span class="s">Params are:</span><span class="se">\n</span><span class="si">%s</span><span class="s">&quot;</span>
                <span class="o">%</span> <span class="p">(</span>
                    <span class="n">e</span><span class="p">,</span>
                    <span class="nb">str</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">p_case</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">_ComputeLnProbEval</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper class to allow emcee to sample in parallel.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gp : :py:class:`GaussianProcess` instance</span>
<span class="sd">        The :py:class:`GaussianProcess` instance to wrap.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gp</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">gp</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the log-probability of the given hyperparameters.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like</span>
<span class="sd">            The new hyperparameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

<span class="k">class</span> <span class="nc">_OptimizeHyperparametersEval</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper class to support parallel random starts of MAP estimation of hyperparameters.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gp : :py:class:`GaussianProcess` instance</span>
<span class="sd">        Instance to wrap to allow parallel optimization of.</span>
<span class="sd">    opt_kwargs : dict</span>
<span class="sd">        Dictionary of keyword arguments to be passed to</span>
<span class="sd">        :py:func:`scipy.optimize.minimize`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">gp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_kwargs</span> <span class="o">=</span> <span class="n">opt_kwargs</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samp</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">,</span>
                <span class="n">samp</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_kwargs</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;scipy.optimize.minimize not available, defaulting &quot;</span>
                          <span class="s">&quot;to fmin_slsqp.&quot;</span><span class="p">,</span>
                          <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">wrap_fmin_slsqp</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">,</span>
                <span class="n">samp</span><span class="p">,</span>
                <span class="n">opt_kwargs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">opt_kwargs</span>
            <span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s">&quot;Minimizer failed, skipping sample. Error is: </span><span class="si">%s</span><span class="s">: </span><span class="si">%s</span><span class="s">. &quot;</span>
                <span class="s">&quot;State of params is: </span><span class="si">%s</span><span class="s">&quot;</span>
                <span class="o">%</span> <span class="p">(</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">free_params</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="ne">RuntimeWarning</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">None</span>

<div class="viewcode-block" id="Constraint"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.Constraint">[docs]</a><span class="k">class</span> <span class="nc">Constraint</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements an inequality constraint on the value of the mean or its derivatives.</span>
<span class="sd">    </span>
<span class="sd">    Provides a callable such as can be passed to SLSQP or COBYLA to implement</span>
<span class="sd">    the constraint when using :py:func:`scipy.optimize.minimize`.</span>
<span class="sd">    </span>
<span class="sd">    The function defaults implement a constraint that forces the mean value to</span>
<span class="sd">    be positive everywhere.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gp : :py:class:`GaussianProcess`</span>
<span class="sd">        The :py:class:`GaussianProcess` instance to create the constraint on.</span>
<span class="sd">    boundary_val : float, optional</span>
<span class="sd">        Boundary value for the constraint. For `type_` = &#39;gt&#39;, this is the lower</span>
<span class="sd">        bound, for `type_` = &#39;lt&#39;, this is the upper bound. Default is 0.0.</span>
<span class="sd">    n : non-negative int, optional</span>
<span class="sd">        Derivative order to evaluate. Default is 0 (value of the mean). Note</span>
<span class="sd">        that non-int values are silently cast to int.</span>
<span class="sd">    loc : {&#39;min&#39;, &#39;max&#39;}, float or Array-like of float (`num_dim`,), optional</span>
<span class="sd">        Which extreme of the mean to use, or location to evaluate at.</span>
<span class="sd">        </span>
<span class="sd">        * If &#39;min&#39;, the minimum of the mean (optionally over `bounds`) is used.</span>
<span class="sd">        * If &#39;max&#39;, the maximum of the mean (optionally over `bounds`) is used.</span>
<span class="sd">        * If a float (valid for `num_dim` = 1 only) or Array of float, the mean</span>
<span class="sd">          is evaluated at the given X value.</span>
<span class="sd">        </span>
<span class="sd">        Default is &#39;min&#39; (use function minimum).</span>
<span class="sd">    type_ : {&#39;gt&#39;, &#39;lt&#39;}, optional</span>
<span class="sd">        What type of inequality constraint to implement.</span>
<span class="sd">        </span>
<span class="sd">        * If &#39;gt&#39;, a greater-than-or-equals constraint is used.</span>
<span class="sd">        * If &#39;lt&#39;, a less-than-or-equals constraint is used.</span>
<span class="sd">        </span>
<span class="sd">        Default is &#39;gt&#39; (greater-than-or-equals).</span>
<span class="sd">    bounds : 2-tuple of float or 2-tuple Array-like of float (`num_dim`,) or None, optional</span>
<span class="sd">        Bounds to use when `loc` is &#39;min&#39; or &#39;max&#39;.</span>
<span class="sd">        </span>
<span class="sd">        * If None, the bounds are taken to be the extremes of the training data.</span>
<span class="sd">          For multivariate data, &quot;extremes&quot; essentially means the smallest</span>
<span class="sd">          hypercube oriented parallel to the axes that encapsulates all of the</span>
<span class="sd">          training inputs. (I.e., ``(gp.X.min(axis=0), gp.X.max(axis=0))``)</span>
<span class="sd">        * If `bounds` is a 2-tuple, then this is used as (`lower`, `upper`)</span>
<span class="sd">          where lower` and `upper` are Array-like with dimensions (`num_dim`,).</span>
<span class="sd">        * If `num_dim` is 1 then `lower` and `upper` can be scalar floats.</span>
<span class="sd">        </span>
<span class="sd">        Default is None (use extreme values of training data).</span>
<span class="sd">    </span>
<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        If `gp` is not an instance of :py:class:`GaussianProcess`.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `n` is negative.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `loc` is not &#39;min&#39;, &#39;max&#39; or an Array-like of the correct dimensions.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `type_` is not &#39;gt&#39; or &#39;lt&#39;.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `bounds` is not None or length 2 or if the elements of bounds don&#39;t</span>
<span class="sd">        have the right dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gp</span><span class="p">,</span> <span class="n">boundary_val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">&#39;min&#39;</span><span class="p">,</span> <span class="n">type_</span><span class="o">=</span><span class="s">&#39;gt&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gp</span><span class="p">,</span> <span class="n">GaussianProcess</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s">&quot;Argument gp must be an instance of GaussianProcess.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">gp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">boundary_val</span> <span class="o">=</span> <span class="n">boundary_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;n must be a non-negative int!&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">loc</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;min&#39;</span><span class="p">,</span> <span class="s">&#39;max&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">iter</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">loc</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Argument loc must be &#39;min&#39;, &#39;max&#39; or an &quot;</span>
                                     <span class="s">&quot;array of length </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loc</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">loc</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">,):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Argument loc must be &#39;min&#39;, &#39;max&#39; or have &quot;</span>
                                     <span class="s">&quot;length </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">type_</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;gt&#39;</span><span class="p">,</span> <span class="s">&#39;lt&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">type_</span> <span class="o">=</span> <span class="n">type_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Argument type_ must be &#39;gt&#39; or &#39;lt&#39;.&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                      <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Argument bounds must have length 2!&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bounds</span><span class="p">)):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="nb">iter</span><span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Each element in argument bounds must &quot;</span>
                                         <span class="s">&quot;have length </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">bounds</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">,):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;Each element in argument bounds must &quot;</span>
                                         <span class="s">&quot;have length </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">num_dim</span><span class="p">)</span>
        <span class="c"># Unfold bounds into the shape needed by minimize:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
<div class="viewcode-block" id="Constraint.__call__"><a class="viewcode-back" href="../../gptools.html#gptools.gaussian_process.Constraint.__call__">[docs]</a>    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a non-negative number if the constraint is satisfied.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : Array-like, length dictated by kernel</span>
<span class="sd">            New parameters to use.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        val : float</span>
<span class="sd">            Value of the constraint. :py:class:`minimize` will attempt to keep</span>
<span class="sd">            this non-negative.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">update_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s">&#39;min&#39;</span><span class="p">,</span> <span class="s">&#39;max&#39;</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">==</span> <span class="s">&#39;max&#39;</span><span class="p">:</span>
                <span class="n">factor</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">factor</span> <span class="o">=</span> <span class="mf">1.0</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">method</span><span class="o">=</span><span class="s">&#39;SLSQP&#39;</span><span class="p">,</span>
                    <span class="n">bounds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">wrap_fmin_slsqp</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">scipy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">opt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;bounds&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="s">&#39;iprint&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
                <span class="p">)</span>
                
            <span class="k">if</span> <span class="ow">not</span> <span class="n">res</span><span class="o">.</span><span class="n">success</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;Solver reports failure, extremum was likely NOT &quot;</span>
                              <span class="s">&quot;found. Status: </span><span class="si">%d</span><span class="s">, Message: &#39;</span><span class="si">%s</span><span class="s">&#39;&quot;</span>
                              <span class="o">%</span> <span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">status</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">message</span><span class="p">),</span>
                              <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">factor</span> <span class="o">*</span> <span class="n">res</span><span class="o">.</span><span class="n">fun</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_</span> <span class="o">==</span> <span class="s">&#39;gt&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">val</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">boundary_val</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">boundary_val</span> <span class="o">-</span> <span class="n">val</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">gptools 0.2 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, Mark Chilenski.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>